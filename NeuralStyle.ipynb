{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SananSuleymanov/Neural_Style_Transfer_video/blob/main/NeuralStyle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AboMbWOSllPQ"
      },
      "source": [
        "**Steps to follow:**\n",
        "1. Load model\n",
        "2. Read style image and preprocess\n",
        "3. Read the frame of the video and preprocess it\n",
        "4. Apply Neural style transfer to the frame \n",
        "5. Reapeat 3 and 4 till the last frame and save it using OpenCV VideoWriter function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN3chac0WFTW"
      },
      "source": [
        "#Required Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_hub\n",
            "  Downloading tensorflow_hub-0.14.0-py2.py3-none-any.whl (90 kB)\n",
            "     ---------------------------------------- 0.0/90.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 90.3/90.3 kB ? eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\sriya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_hub) (1.23.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\sriya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_hub) (4.23.4)\n",
            "Installing collected packages: tensorflow_hub\n",
            "Successfully installed tensorflow_hub-0.14.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow_hub "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2bx7Ml25WE3S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5Ga0HNGS2SY"
      },
      "source": [
        "#Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MpC9coVGS6to"
      },
      "outputs": [],
      "source": [
        "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72ilBhK0QIa2"
      },
      "source": [
        "#Processing image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hOIlkH-HoWfs"
      },
      "outputs": [],
      "source": [
        "#read image, convert to tensor, normalize and resize \n",
        "def image_read(image):\n",
        "  max_dim=512\n",
        "  image= tf.convert_to_tensor(image, dtype = tf.float32)\n",
        "  image= image/255.0\n",
        "  shape = tf.cast(tf.shape(image)[:-1], tf.float32)\n",
        "  long_dim = max(shape)\n",
        "  scale = max_dim/long_dim\n",
        "  new_shape = tf.cast(shape*scale, tf.int32)\n",
        "  new_image = tf.image.resize(image, new_shape)\n",
        "  new_image = new_image[tf.newaxis, :]\n",
        "  \n",
        "  return new_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LnLRvvG1m7X7"
      },
      "outputs": [],
      "source": [
        "#convert tensor to numpy array\n",
        "def tensor_toimage(tensor):\n",
        "  tensor =tensor*255\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0]==1\n",
        "    tensor=tensor[0]\n",
        "\n",
        "  return tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYcnyKVdSm-d"
      },
      "source": [
        "#Reading style image and content video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Lkz-mP-whiVH"
      },
      "outputs": [],
      "source": [
        "style_im = cv2.imread(\"style.jpg\")\n",
        "style_im = cv2.cvtColor(style_im, cv2.COLOR_BGR2RGB)\n",
        "style_im = image_read(style_im)\n",
        "\n",
        "cap = cv2.VideoCapture(\"content.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_lkPPjiovq6"
      },
      "source": [
        "#Transfer Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "38KTlUdwlx0G"
      },
      "outputs": [],
      "source": [
        "#in order to get the size of width and shape of video, we used first frame of video\n",
        "ret, frame = cap.read()\n",
        "frame_width = image_read(frame)[0].shape[1]\n",
        "frame_height= image_read(frame)[0].shape[0]\n",
        "\n",
        "out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'XVID'), 10, \n",
        "                      (frame_width,frame_height))\n",
        "\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame = image_read(frame)\n",
        "    stylized_frame = hub_model(tf.constant(frame), tf.constant(style_im))[0]\n",
        "    image = tensor_toimage(stylized_frame)\n",
        "    out.write(image)\n",
        "  else:\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOGF5Lwy9G3LXd0qBBPqk+d",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
